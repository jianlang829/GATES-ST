=== é¡¹ç›®æ ¸å¿ƒæ–‡ä»¶å†…å®¹æ±‡æ€» ===


============================================================
æ–‡ä»¶: .gitignore
============================================================

# Directories
data/
logs/
cache/
results/

# Large file extensions
*.zip
*.tar.gz
*.h5
*.h5ad      # ğŸ‘ˆ æ˜¾å¼åŠ ä¸Š .h5adï¼ˆä½ å‡ºé—®é¢˜çš„æ–‡ä»¶ç±»å‹ï¼‰
*.pt
*.pth
*.onnx
*.pb

# Python
*.pyc
__pycache__/

# Text files (only if truly temporary)
default_yaml.txt
gates_model.txt
run_analysis.txt
trainer.txt
utils.txt



============================================================
æ–‡ä»¶: README.md
============================================================

# GATES Project: Graph Attention Transcriptomics Encoder for Spatial Transcriptomics Analysis

GATESï¼ˆGraph Attention Transcriptomics Encoderï¼‰æ˜¯ä¸€ä¸ªåŸºäº **PyTorch Geometric** çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç”¨äºåˆ†æ **ç©ºé—´è½¬å½•ç»„å­¦ï¼ˆSpatial Transcriptomicsï¼‰** æ•°æ®ã€‚æœ¬é¡¹ç›®ç»“åˆç©ºé—´é‚»æ¥å…³ç³»ä¸åŸºå› è¡¨è¾¾ç›¸ä¼¼æ€§ï¼Œæ„å»ºå¼‚æ„å›¾ç»“æ„ï¼Œå¹¶é€šè¿‡å›¾æ³¨æ„åŠ›æœºåˆ¶è¿›è¡Œç‰¹å¾å­¦ä¹ ï¼Œæœ€ç»ˆå®ç°é«˜ç²¾åº¦çš„ç»„ç»‡åŒºåŸŸèšç±»ä¸å¯è§†åŒ–ã€‚

## ğŸ“Œ é¡¹ç›®äº®ç‚¹
- æ”¯æŒ 10x Genomics Visium ç­‰ä¸»æµç©ºé—´è½¬å½•ç»„æ•°æ®æ ¼å¼
- è‡ªåŠ¨æ„å»º **ç©ºé—´é‚»æ¥å›¾ + åŸºå› ç›¸ä¼¼æ€§å›¾**
- åŸºäº **GATï¼ˆGraph Attention Networkï¼‰** çš„ç«¯åˆ°ç«¯è®­ç»ƒ
- æä¾›å®Œæ•´çš„é¢„å¤„ç† â†’ è®­ç»ƒ â†’ èšç±» â†’ å¯è§†åŒ–æµç¨‹
- æ¨¡å—åŒ–è®¾è®¡ï¼Œæ˜“äºæ‰©å±•ä¸å¤ç”¨

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
C:.
â”‚  .gitignore
â”‚  LICENSE
â”‚  README.md
â”‚  requirements.txt
â”‚
â”œâ”€cache                     # é¢„å¤„ç†åçš„ç¼“å­˜æ•°æ®ï¼ˆ.h5adï¼‰
â”œâ”€configs                   # é…ç½®æ–‡ä»¶ï¼ˆYAMLï¼‰
â”œâ”€data                      # åŸå§‹æ•°æ®ï¼ˆæ”¯æŒå¤šä¸ªæ ·æœ¬ï¼Œå¦‚ 151673, 151674, 151675ï¼‰
â”‚  â””â”€151673                 # ç¤ºä¾‹ï¼š10x Visium å°é¼ è„‘åˆ‡ç‰‡æ•°æ®
â”‚      â”‚  filtered_feature_bc_matrix.h5
â”‚      â”‚  position.tsv
â”‚      â”‚  metadata.tsv
â”‚      â”‚  truth.txt         # çœŸå®æ ‡ç­¾ï¼ˆç”¨äºè¯„ä¼°ï¼‰
â”‚      â””â”€spatial/
â”œâ”€results                   # è¾“å‡ºç»“æœï¼ˆå¦‚èšç±»å›¾ï¼‰
â”œâ”€scripts                   # ä¸»è¿è¡Œè„šæœ¬
â”‚  â””â”€run_analysis.py
â””â”€src                       # æ ¸å¿ƒæºç 
    â”‚  gates_model.py       # GATES æ¨¡å‹å®šä¹‰
    â”‚  trainer.py           # è®­ç»ƒé€»è¾‘
    â”‚  utils.py             # å·¥å…·å‡½æ•°ï¼ˆå›¾æ„å»ºã€é¢„å¤„ç†ç­‰ï¼‰
    â”‚  pyg.py               # PyG å›¾æ•°æ®å°è£…
    â””â”€convert_visium_to_stereo.py  # æ•°æ®æ ¼å¼è½¬æ¢å·¥å…·
```

---

## âš™ï¸ å®‰è£…æŒ‡å—

### ç¯å¢ƒè¦æ±‚
- Python â‰¥ 3.8
- PyTorch â‰¥ 1.12
- CUDAï¼ˆæ¨èï¼Œç”¨äºåŠ é€Ÿè®­ç»ƒï¼‰

### å®‰è£…æ­¥éª¤
```bash
# 1. å…‹éš†ä»“åº“
git clone https://github.com/your-username/GATES.git
cd GATES

# 2. å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

> ğŸ’¡ æç¤ºï¼šå»ºè®®ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒï¼ˆå¦‚ `conda` æˆ– `venv`ï¼‰é¿å…ä¾èµ–å†²çªã€‚

---

## â–¶ï¸ å¿«é€Ÿå¼€å§‹

```bash
cd scripts
python run_analysis.py
```

è¯¥è„šæœ¬å°†è‡ªåŠ¨ï¼š
1. åŠ è½½ `data/151673` ä¸­çš„ Visium æ•°æ®
2. é¢„å¤„ç†å¹¶ç¼“å­˜åˆ° `cache/`
3. æ„å»ºç©ºé—´å›¾ä¸åŸºå› ç›¸ä¼¼å›¾
4. è®­ç»ƒ GATES æ¨¡å‹
5. æ‰§è¡Œèšç±»å¹¶è¯„ä¼°ï¼ˆSilhouette Score, Davies-Bouldin Indexï¼‰
6. ä¿å­˜ç©ºé—´èšç±»å›¾è‡³ `results/spatial_plot.png`

---

## ğŸ›  é…ç½®è¯´æ˜

æ‰€æœ‰å‚æ•°å‡åœ¨ `configs/default.yaml` ä¸­ç®¡ç†ï¼ŒåŒ…æ‹¬ï¼š

```yaml
# configs/default.yaml
data:
  counts_file: 'C:/Users/admini/Documents/GATES-ST/data/151673/RNA_counts.tsv'
  coor_file: 'C:/Users/admini/Documents/GATES-ST/data/151673/position.tsv'
  used_barcodes_file: 'C:/Users/admini/Documents/GATES-ST/data/151673/used_barcodes.txt'
model:
  alpha: 0.5  # ä¿®æ­£ï¼šåŸå€¼ 0.0001 è¿‡å°ï¼Œå»ºè®® 0.1~0.9
  n_top_genes: 3000
  hidden_dims: [512, 30]
  rad_cutoff: 50
  k_neighbors: 6
  similarity_metric: "cosine"
train:
  n_epochs: 1000
  lr: 0.0001
  weight_decay: 0.0001
  key_added: "GATES"
cluster:
  resolution: 1.0
output:
  spatial_plot_path: "results/spatial_plot.png"
  neighbor_stats_plot: 'C:/Users/admini/Documents/GATES-ST/figure/alpha{alpha}_{resolution}_Stereo-seq_Mouse_NumberOfNeighbors.png'
  spatial_plot_crop: [10100, 10721, 13810, 13093]

```

ä¿®æ”¹è¯¥æ–‡ä»¶å³å¯é€‚é…ä¸åŒæ•°æ®é›†æˆ–è°ƒæ•´è¶…å‚æ•°ã€‚

---

## ğŸ“ˆ è¾“å‡ºç»“æœ

è¿è¡Œå®Œæˆåï¼Œä½ å°†è·å¾—ï¼š
- **èšç±»æŒ‡æ ‡**ï¼šæ§åˆ¶å°è¾“å‡º Silhouette Score å’Œ Davies-Bouldin Index
- **å¯è§†åŒ–å›¾**ï¼š`results/spatial_plot.png` å±•ç¤ºç©ºé—´èšç±»ç»“æœï¼ˆå¦‚ä¸‹ç¤ºæ„ï¼‰

> ğŸ–¼ï¸ *ç¤ºä¾‹å›¾ï¼šä¸åŒé¢œè‰²ä»£è¡¨ä¸åŒç»„ç»‡åŒºåŸŸï¼Œä¸çœŸå®è§£å‰–ç»“æ„é«˜åº¦ä¸€è‡´*

---

## ğŸ“š æ•°æ®è¯´æ˜

æœ¬é¡¹ç›®é»˜è®¤ä½¿ç”¨ **10x Genomics Visium å…¬å¼€æ•°æ®é›†**ï¼š
- `151673`, `151674`, `151675`ï¼šå°é¼ è„‘ç»„ç»‡åˆ‡ç‰‡ï¼ˆæ¥è‡ª [10xå®˜æ–¹ç¤ºä¾‹](https://support.10xgenomics.com/spatial-gene-expression/datasets)ï¼‰
- æ–‡ä»¶åŒ…æ‹¬ï¼šåŸºå› è¡¨è¾¾çŸ©é˜µï¼ˆ.h5ï¼‰ã€ç©ºé—´åæ ‡ï¼ˆtissue_positions_list.csvï¼‰ã€ç»„ç»‡å›¾åƒç­‰

å¦‚éœ€ä½¿ç”¨å…¶ä»–æ•°æ®ï¼ˆå¦‚ Stereo-seqï¼‰ï¼Œè¯·å‚è€ƒ `src/convert_visium_to_stereo.py` è¿›è¡Œæ ¼å¼è½¬æ¢ã€‚

---

## â“ å¸¸è§é—®é¢˜

**Q: è¿è¡Œæ—¶æŠ¥é”™ â€œCUDA out of memoryâ€ï¼Ÿ**
A: å°è¯•å‡å° `batch_size`ï¼ˆå¦‚æœ‰ï¼‰æˆ–æ”¹ç”¨ `device: "cpu"`ã€‚

**Q: å¦‚ä½•æ›´æ¢æ•°æ®é›†ï¼Ÿ**
A: ä¿®æ”¹ `configs/default.yaml` ä¸­çš„ `data.root` è·¯å¾„ï¼Œå¹¶ç¡®ä¿ç›®å½•ç»“æ„ä¸ 151673 ä¸€è‡´ã€‚

**Q: èƒ½å¦ç”¨äºäººç±»ç»„ç»‡æ•°æ®ï¼Ÿ**
A: å¯ä»¥ï¼åªè¦æä¾›ç¬¦åˆæ ¼å¼çš„ç©ºé—´è¡¨è¾¾æ•°æ®å³å¯ã€‚

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ **MIT License** â€” è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

---

## ğŸ™ è‡´è°¢

- æ•°æ®æ¥æºï¼š10x Genomics Spatial Gene Expression Datasets
- æŠ€æœ¯åŸºç¡€ï¼šPyTorch Geometric, Scanpy, scikit-learn
- è‹¥æœ¬é¡¹ç›®å¯¹æ‚¨çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼Œæ¬¢è¿å¼•ç”¨ç›¸å…³è®ºæ–‡ï¼ˆå¦‚æœ‰ï¼‰ï¼

---

> ğŸ’¬ **æ¬¢è¿æäº¤ Issue æˆ– Pull Requestï¼** ä»»ä½•æ”¹è¿›å»ºè®®æˆ– bug æŠ¥å‘Šéƒ½ååˆ†æ„Ÿè°¢ï¼



============================================================
æ–‡ä»¶: configs/default.yaml
============================================================

# configs/default.yaml
data:
  counts_file: 'data/151673/RNA_counts.tsv'
  coor_file: 'data/151673/position.tsv'
  used_barcodes_file: 'data/151673/used_barcodes.txt'
model:
  alpha: 0.5  # ä¿®æ­£ï¼šåŸå€¼ 0.0001 è¿‡å°ï¼Œå»ºè®® 0.1~0.9
  n_top_genes: 3000
  hidden_dims: [512, 30]
  rad_cutoff: 50
  k_neighbors: 6
  similarity_metric: "cosine"
train:
  n_epochs: 10
  lr: 0.0001
  weight_decay: 0.0001
  lambda_spatial: 0.1
  key_added: "GATES"
cluster:
  resolution: 1.0
output:
  spatial_plot_path: "results/spatial_plot.png"
  neighbor_stats_plot: 'figure/alpha{alpha}_{resolution}_Stereo-seq_Mouse_NumberOfNeighbors.png'
  spatial_plot_crop: null



============================================================
æ–‡ä»¶: configs/requirements.txt
============================================================

[æ— æ³•è¯»å–äºŒè¿›åˆ¶æ–‡ä»¶æˆ–ç¼–ç é”™è¯¯: .\configs/requirements.txt]


============================================================
æ–‡ä»¶: scripts/run_analysis.py
============================================================

# scripts/run_analysis.py
import os
import yaml
import scanpy as sc
import matplotlib.pyplot as plt
from sklearn.metrics import silhouette_score, davies_bouldin_score
from src.utils import load_and_preprocess_data, Cal_Spatial_Net, Stats_Spatial_Net, Cal_Gene_Similarity_Net, create_pyg_data
from src.gates_model import GATES
from src.trainer import GATESTrainer
import squidpy as sq

def main():
    with open('./configs/default.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    # === æ–°å¢ï¼šå®šä¹‰ç¼“å­˜è·¯å¾„ ===
    cache_dir = "./cache"
    os.makedirs(cache_dir, exist_ok=True)
    cache_file = os.path.join(
        cache_dir,
        f"preprocessed_adata_rad{config['model']['rad_cutoff']}_k{config['model']['k_neighbors']}.h5ad"
    )

    print('------------------')
    alpha = config['model']['alpha']
    resolution = config['cluster']['resolution']

    # === æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨ ===
    if os.path.exists(cache_file):
        print(f"Loading cached preprocessed data from {cache_file}...")
        adata = sc.read_h5ad(cache_file)
        print(f'Loaded cached data: {adata.shape}')
    else:
        print("Loading and preprocessing data...")
        adata = load_and_preprocess_data(config)
        print(f'After filtering: {adata.shape}')

        print("Building spatial network...")
        Cal_Spatial_Net(adata, rad_cutoff=config['model']['rad_cutoff'], model='Radius', verbose=True)
        Stats_Spatial_Net(adata, save_path=config['output']['neighbor_stats_plot'].format(alpha=alpha, resolution=resolution), show_plot=False)

        print("Building gene similarity network...")
        Cal_Gene_Similarity_Net(
            adata,
            k_neighbors=config['model']['k_neighbors'],
            metric=config['model']['similarity_metric'],
            verbose=True
        )

        # === ä¿å­˜åˆ°ç¼“å­˜ ===
        print(f"Saving preprocessed data to cache: {cache_file}")
        adata.write_h5ad(cache_file)
    print("Preparing PyG data...")
    pyg_data = create_pyg_data(adata, config)
    # ç¡®ä¿è¾“å…¥ç»´åº¦æ­£ç¡®ï¼šé«˜å˜åŸºå› æ•°é‡
    in_channels = adata.var['highly_variable'].sum() if 'highly_variable' in adata.var else adata.n_vars
    hidden_channels = config['model']['hidden_dims'][0]
    out_channels = config['model']['hidden_dims'][1]
    print(f"Model input dim: {in_channels}, hidden: {hidden_channels}, output: {out_channels}")
    print("Initializing and training GATES model...")
    print("hidden_dims:", config['model']['hidden_dims'])
    print("type:", type(config['model']['hidden_dims']))
    model = GATES(
        in_channels = int(adata.var['highly_variable'].sum()) if 'highly_variable' in adata.var else int(adata.n_vars),
        hidden_channels = int(config['model']['hidden_dims'][0]),
        out_channels = int(config['model']['hidden_dims'][1]),
        alpha=alpha
    )
    trainer = GATESTrainer(model, config)
    trainer.train(pyg_data, n_epochs=config['train']['n_epochs'])
    print("Inferring embeddings...")
    embeddings = trainer.infer(pyg_data)
    adata.obsm[config['train']['key_added']] = embeddings
    print("Performing clustering and UMAP...")
    sc.pp.neighbors(adata, use_rep=config['train']['key_added'])
    sc.tl.umap(adata)
    sc.tl.louvain(adata, resolution=resolution)
    adata.obs['louvain'] = adata.obs['louvain'].astype('category')  # ğŸ‘ˆ æ–°å¢è¿™è¡Œï¼
    louvain_labels = adata.obs['louvain'].astype(int)

    # ä¿®æ­£ï¼šä½¿ç”¨ GATES åµŒå…¥è®¡ç®—æŒ‡æ ‡ï¼Œè€Œé UMAP
    sc_score = silhouette_score(embeddings, louvain_labels)
    db_score = davies_bouldin_score(embeddings, louvain_labels)

    print(f'Silhouette Coefficient: {sc_score:.4f}')
    print(f'Davies-Bouldin Index: {db_score:.4f}')
    print("Generating plots...")
    crop_coord = config['output']['spatial_plot_crop']
    plt.rcParams["figure.figsize"] = (5, 4)

    print("Generating plots...")
    crop_coord = config['output']['spatial_plot_crop']
    plt.rcParams["figure.figsize"] = (5, 4)

    # ä¼˜å…ˆä» config è·å–å®Œæ•´è·¯å¾„ï¼Œå¦åˆ™ç”¨é»˜è®¤å + è¾“å‡ºç›®å½•
    output_path = config['output'].get('spatial_plot_path')
    if output_path is None:
        output_dir = config['output'].get('dir', '.')
        output_path = os.path.join(output_dir, "spatial_louvain.png")

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    print("Spatial coordinates range:")
    print("x:", adata.obsm["spatial"][:, 0].min(), "to", adata.obsm["spatial"][:, 0].max())
    print("y:", adata.obsm["spatial"][:, 1].min(), "to", adata.obsm["spatial"][:, 1].max())
    print("Crop coord:", crop_coord)
    print("Spatial coordinates shape:", adata.obsm["spatial"].shape)
    print("First few spatial coords:\n", adata.obsm["spatial"][:5])
    print("Louvain labels info:")
    print("Unique labels:", adata.obs['louvain'].unique())
    print("Number of NaNs:", adata.obs['louvain'].isna().sum())
    print("Data type:", adata.obs['louvain'].dtype)

    # æ›¿æ¢åŸæ¥çš„ sc.pl.spatial è°ƒç”¨
    sq.pl.spatial_scatter(
        adata,
        color="louvain",
        shape=None,  # ä¸æ˜¾ç¤ºç»„ç»‡è½®å»“ï¼ˆå¯é€‰ï¼‰
        size=20,     # å¯¹åº” spot_size
        title=f'Ours SC{sc_score:.2f} DB{db_score:.2f}',
        save=output_path  # è‡ªåŠ¨ä¿å­˜ï¼Œæ— éœ€ plt.savefig
    )

    plt.axis('off')
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"Spatial plot saved to: {output_path}")
    success_art = r"""


    ___ _   _  ___ ___ ___  ___ ___
    / __| | | |/ __/ __/ _ \/ __/ __|
    \__ \ |_| | (_| (_|  __/\__ \__ \
    |___/\__,_|\___\___\___||___/___/


    """

    print("\033[1;32m" + success_art + "\033[0m")
    print("\033[1;36mâœ¨ Analysis completed successfully! All results saved. âœ¨\033[0m")
    print("\033[1;33mğŸ‰ You're awesome! Go celebrate with a coffee! â˜•\033[0m")

if __name__ == "__main__":
    main()



============================================================
æ–‡ä»¶: src/Check_gpu_available.py
============================================================

## torch
import torch

# æ£€æŸ¥ CUDA æ˜¯å¦å¯ç”¨
print(f"CUDA available: {torch.cuda.is_available()}")

# æ£€æŸ¥å¯ç”¨çš„ GPU æ•°é‡
print(f"Number of GPUs: {torch.cuda.device_count()}")

# è·å–å½“å‰ GPU è®¾å¤‡ç´¢å¼•
if torch.cuda.is_available():
    print(f"Current GPU: {torch.cuda.current_device()}")
    print(f"GPU name: {torch.cuda.get_device_name(torch.cuda.current_device())}")

    # åˆ›å»ºä¸€ä¸ªåœ¨ GPU ä¸Šçš„å¼ é‡æ¥æµ‹è¯•
    x = torch.randn(1000, 1000).cuda()
    y = torch.randn(1000, 1000).cuda()
    z = torch.mm(x, y)
    print("GPU computation test passed!")



============================================================
æ–‡ä»¶: src/convert_visium_to_stereo.py
============================================================

import sys
sys.modules['torch'] = None  # é˜»æ­¢ anndata å¯¼å…¥ torch

import scanpy as sc
import pandas as pd
import os
# ... åç»­ä»£ç ä¸å˜
import scanpy as sc
import pandas as pd
import os

print("å¼€å§‹è½¬æ¢...")
# ===== é…ç½®è·¯å¾„ =====
input_h5 = r"C:\Users\admini\Documents\GATES-ST\data\151673\filtered_feature_bc_matrix.h5"
input_pos = r"C:\Users\admini\Documents\GATES-ST\data\151673\spatial\tissue_positions_list.csv"
output_dir = r"C:\Users\admini\Documents\GATES-ST\data\151673"

# ===== 1. è¯»å–è¡¨è¾¾çŸ©é˜µ =====
adata = sc.read_10x_h5(input_h5)
# è½¬ç½®ï¼šè¡Œ=åŸºå› ï¼Œåˆ—=barcodeï¼ˆTSV é€šå¸¸è¿™æ ·ï¼‰
df_counts = adata.to_df().T  # shape: (n_genes, n_barcodes)
df_counts.to_csv(os.path.join(output_dir, "RNA_counts.tsv"), sep="\t")

print("RNA_counts.tsv å·²ä¿å­˜")
# ===== 2. è¯»å–åæ ‡æ–‡ä»¶ =====
# Visium çš„ tissue_positions_list.csv æ ¼å¼ï¼ˆæ—  headerï¼‰ï¼š
# barcode, in_tissue, array_row, array_col, pxl_row_in_fullres, pxl_col_in_fullres
pos_df = pd.read_csv(input_pos, header=None)
pos_df.columns = ["barcode", "in_tissue", "array_row", "array_col", "pxl_row", "pxl_col"]

# åªä¿ç•™ in_tissue == 1 çš„ spotsï¼ˆå³ç»„ç»‡å†…çš„æœ‰æ•ˆç‚¹ï¼‰
used_barcodes = pos_df[pos_df["in_tissue"] == 1]["barcode"].tolist()

# ä¿å­˜ used_barcodes.txt
with open(os.path.join(output_dir, "used_barcodes.txt"), "w") as f:
    f.write("\n".join(used_barcodes))

print("âœ… å·²ä¿å­˜ used_barcodes.txt")
# ä¿å­˜ position.tsvï¼ˆæ ¼å¼ï¼šbarcode, x, yï¼‰
# æ³¨æ„ï¼šVisium åæ ‡å¸¸ç”¨ pxl_col (x), pxl_row (y)ï¼Œä½†æœ‰äº›å·¥å…·ç”¨ array_col/array_row
# è¿™é‡Œç”¨é«˜åˆ†è¾¨ç‡å›¾åƒåæ ‡ï¼ˆpxl_col, pxl_rowï¼‰ï¼Œä½ ä¹Ÿå¯ä»¥æ ¹æ®éœ€æ±‚æ¢
# âœ… æ­£ç¡®ï¼šä½¿ç”¨é«˜åˆ†è¾¨ç‡åƒç´ åæ ‡ (pxl_col, pxl_row)
pos_used = pos_df[pos_df["in_tissue"] == 1][["barcode", "pxl_col", "pxl_row"]]
pos_used.to_csv(os.path.join(output_dir, "position.tsv"), sep="\t", index=False, header=False)

print("âœ… ä¸‰ä¸ªæ–‡ä»¶å·²ç”Ÿæˆï¼")
print("- RNA_counts.tsv")
print("- position.tsv")
print("- used_barcodes.txt")



============================================================
æ–‡ä»¶: src/gates_model.py
============================================================

# src/gates_model.py
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GATConv

class GATES(nn.Module):
    """
    GATES (Graph Attention Encoder) æ¨¡å‹
    ä½¿ç”¨ä¸¤ä¸ªç‹¬ç«‹çš„ GAT å±‚åˆ†åˆ«å¤„ç†ç©ºé—´ç½‘ç»œå’ŒåŸºå› ç›¸ä¼¼æ€§ç½‘ç»œï¼Œç„¶åè¿›è¡ŒåŠ æƒèåˆã€‚
    """
    def __init__(self, in_channels: int, hidden_channels: int, out_channels: int, alpha: float = 0.5):
        """
        åˆå§‹åŒ–æ¨¡å‹ã€‚
        Args:
            in_channels: è¾“å…¥ç‰¹å¾ç»´åº¦
            hidden_channels: éšè—å±‚ç»´åº¦
            out_channels: è¾“å‡ºåµŒå…¥ç»´åº¦
            alpha: åŸºå› ç›¸ä¼¼æ€§ç½‘ç»œçš„æƒé‡ï¼Œæœ€ç»ˆèåˆä¸º: alpha * gene_sim + (1-alpha) * spatial
        """
        super().__init__()
        self.alpha = alpha
        # ç¼–ç å™¨éƒ¨åˆ†
        self.spatial_gat = GATConv(in_channels, hidden_channels, add_self_loops=True, concat=False)
        self.gene_sim_gat = GATConv(in_channels, hidden_channels, add_self_loops=True, concat=False)
        self.fusion_gat = GATConv(hidden_channels, out_channels, add_self_loops=True, concat=False)
        # è§£ç å™¨ï¼šç”¨äºé‡æ„è¾“å…¥ï¼ˆä»…è®­ç»ƒæ—¶ä½¿ç”¨ï¼‰
        self.decoder = nn.Sequential(
            nn.Linear(out_channels, hidden_channels),
            nn.ELU(),
            nn.Linear(hidden_channels, in_channels)
        )

    def forward(self, x: torch.Tensor, spatial_edge_index: torch.Tensor, gene_sim_edge_index: torch.Tensor):
        """
        è¿”å›åµŒå…¥å’Œé‡æ„è¾“å‡ºï¼ˆç”¨äºè®­ç»ƒï¼‰
        """
        h_spatial = F.elu(self.spatial_gat(x, spatial_edge_index))
        h_gene_sim = F.elu(self.gene_sim_gat(x, gene_sim_edge_index))
        h_fused = self.alpha * h_gene_sim + (1 - self.alpha) * h_spatial
        # ä½¿ç”¨ç©ºé—´å›¾è¿›è¡Œæœ€ç»ˆèåˆï¼ˆç¬¦åˆç©ºé—´è½¬å½•ç»„ç‰¹æ€§ï¼‰
        embeddings = self.fusion_gat(h_fused, spatial_edge_index)
        recon = self.decoder(embeddings)
        return embeddings, recon

    def encode(self, x: torch.Tensor, spatial_edge_index: torch.Tensor, gene_sim_edge_index: torch.Tensor):
        """
        ä»…è¿”å›åµŒå…¥ï¼ˆç”¨äºæ¨ç†ï¼‰
        """
        h_spatial = F.elu(self.spatial_gat(x, spatial_edge_index))
        h_gene_sim = F.elu(self.gene_sim_gat(x, gene_sim_edge_index))
        h_fused = self.alpha * h_gene_sim + (1 - self.alpha) * h_spatial
        embeddings = self.fusion_gat(h_fused, spatial_edge_index)
        return embeddings



============================================================
æ–‡ä»¶: src/pyg.py
============================================================

import torch

torch_version = torch.__version__.split('+')[0]
cuda_version = torch.version.cuda
cuda_str = f"cu{cuda_version.replace('.', '')}" if cuda_version else "cpu"

print(f"pip install torch_geometric torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-{torch_version}+{cuda_str}.html")



============================================================
æ–‡ä»¶: src/trainer.py
============================================================

# src/trainer.py
import torch
import torch.optim as optim
from tqdm import tqdm
from .gates_model import GATES
from typing import Dict, Any
import torch.nn.functional as F
from torch_geometric.data import Data

class GATESTrainer:
    """
    GATES æ¨¡å‹è®­ç»ƒå™¨
    """
    def __init__(self, model: GATES, config: Dict[str, Any]):
        self.model = model
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        self.optimizer = optim.Adam(
            self.model.parameters(),
            lr=config['train']['lr'],
            weight_decay=config['train']['weight_decay']
        )
        self.loss_history = []

    def train(self, data: Data, n_epochs: int) -> None:
        """
        è®­ç»ƒæ¨¡å‹ã€‚
        Args:
            data: PyG Data å¯¹è±¡ï¼ˆä¸æ˜¯ DataLoaderï¼‰
            n_epochs: è®­ç»ƒè½®æ•°
        """
        self.model.train()
        data = data.to(self.device)
        spatial_edge_index = data.spatial_edge_index  # [2, E]

        # ä»é…ç½®ä¸­è¯»å–ç©ºé—´æ­£åˆ™åŒ–æƒé‡ï¼ˆé»˜è®¤ä¸º 0.0ï¼Œå³ä¸å¯ç”¨ï¼‰
        lambda_spatial = self.config['train'].get('lambda_spatial', 0.0)

        for epoch in tqdm(range(n_epochs), desc="Training"):
            self.optimizer.zero_grad()
            embeddings, recon = self.model(data.x, spatial_edge_index, data.gene_sim_edge_index)

            # 1. é‡æ„æŸå¤±ï¼ˆMSEï¼‰
            recon_loss = F.mse_loss(recon, data.x)

            # 2. ç©ºé—´ä¸€è‡´æ€§æ­£åˆ™é¡¹ï¼ˆä»…å½“ lambda_spatial > 0 æ—¶è®¡ç®—ï¼‰
            spatial_loss = 0.0
            if lambda_spatial > 0.0:
                z_i = embeddings[spatial_edge_index[0]]  # source èŠ‚ç‚¹åµŒå…¥
                z_j = embeddings[spatial_edge_index[1]]  # target èŠ‚ç‚¹åµŒå…¥
                spatial_loss = F.mse_loss(z_i, z_j)      # ||z_i - z_j||^2 çš„å‡å€¼

            # 3. æ€»æŸå¤±
            total_loss = recon_loss + lambda_spatial * spatial_loss

            total_loss.backward()
            self.optimizer.step()
            self.loss_history.append(total_loss.item())

            if epoch % 100 == 0:
                print(f"Epoch {epoch}, Recon Loss: {recon_loss.item():.4f}", end="")
                if lambda_spatial > 0.0:
                    print(f", Spatial Loss: {spatial_loss.item():.4f}", end="")
                print(f", Total Loss: {total_loss.item():.4f}")

    def infer(self, data: Data) -> torch.Tensor:
        """
        ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚
        """
        self.model.eval()
        data = data.to(self.device)
        with torch.no_grad():
            embeddings = self.model.encode(data.x, data.spatial_edge_index, data.gene_sim_edge_index)
        return embeddings.cpu().numpy()



============================================================
æ–‡ä»¶: src/utils.py
============================================================

# src/utils.py
import os
import pandas as pd
import numpy as np
import scanpy as sc
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
from scipy.stats import pearsonr
import matplotlib.pyplot as plt
from typing import Tuple
import torch
from torch_geometric.data import Data
import sklearn

def load_and_preprocess_data(config: dict) -> sc.AnnData:
    # 1. æ£€æŸ¥å¹¶åŠ è½½è®¡æ•°çŸ©é˜µ
    counts_file = config['data']['counts_file']
    if not os.path.exists(counts_file):
        raise FileNotFoundError(f"è®¡æ•°çŸ©é˜µæ–‡ä»¶ä¸å­˜åœ¨: {counts_file}")

    try:
        counts = pd.read_csv(counts_file, sep='\t', index_col=0)
    except Exception as e:
        raise ValueError(f"æ— æ³•è¯»å–è®¡æ•°çŸ©é˜µæ–‡ä»¶ '{counts_file}'ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦ä¸ºåˆ¶è¡¨ç¬¦åˆ†éš”çš„æ–‡æœ¬æ–‡ä»¶ï¼ˆTSVï¼‰ï¼Œä¸”ç¬¬ä¸€åˆ—ä¸ºåŸºå› åã€‚é”™è¯¯è¯¦æƒ…: {e}")

    # 2. æ£€æŸ¥å¹¶åŠ è½½åæ ‡æ–‡ä»¶
    coor_file = config['data']['coor_file']
    if not os.path.exists(coor_file):
        raise FileNotFoundError(f"ç©ºé—´åæ ‡æ–‡ä»¶ä¸å­˜åœ¨: {coor_file}")

    try:
        coor_df = pd.read_csv(coor_file, sep='\t', header=None)
    except Exception as e:
        raise ValueError(f"æ— æ³•è¯»å–åæ ‡æ–‡ä»¶ '{coor_file}'ï¼Œè¯·ç¡®ä¿å…¶ä¸ºåˆ¶è¡¨ç¬¦åˆ†éš”çš„ä¸‰åˆ—æ–‡æœ¬æ–‡ä»¶ï¼ˆbarcode, x, yï¼‰ï¼Œæ— è¡¨å¤´ã€‚é”™è¯¯è¯¦æƒ…: {e}")

    if coor_df.shape[1] < 3:
        raise ValueError(f"åæ ‡æ–‡ä»¶ '{coor_file}' è‡³å°‘åº”åŒ…å«ä¸‰åˆ—ï¼ˆbarcode, x, yï¼‰ï¼Œå½“å‰åªæœ‰ {coor_df.shape[1]} åˆ—ã€‚")

    coor_df.columns = ['barcode', 'x', 'y']
    coor_df = coor_df.set_index('barcode')

    # 3. ç¡®ä¿ç´¢å¼•ç±»å‹ä¸€è‡´ï¼ˆå­—ç¬¦ä¸²ï¼‰
    counts.columns = counts.columns.astype(str)
    coor_df.index = coor_df.index.astype(str)

    # 4. åˆ›å»º AnnDataï¼ˆcells Ã— genesï¼‰
    adata = sc.AnnData(counts.T)
    adata.var_names_make_unique()

    # 5. å¯¹é½è¡¨è¾¾æ•°æ®å’Œåæ ‡ï¼ˆå–äº¤é›†ï¼‰
    common_barcodes = adata.obs_names.intersection(coor_df.index)
    if len(common_barcodes) == 0:
        raise ValueError("è®¡æ•°çŸ©é˜µçš„åˆ—åï¼ˆç»†èƒbarcodeï¼‰ä¸åæ ‡æ–‡ä»¶çš„barcodeæ— äº¤é›†ï¼Œè¯·æ£€æŸ¥ä¸¤è€…æ˜¯å¦åŒ¹é…ã€‚")

    adata = adata[common_barcodes, :]
    coor_df = coor_df.loc[common_barcodes]

    # 6. è®¾ç½®ç©ºé—´åæ ‡ [x, y]
    adata.obsm["spatial"] = coor_df[['x', 'y']].values

    # 7. QC å’Œæ ‡å‡†åŒ–ï¼ˆä¿æŒä¸å˜ï¼‰
    sc.pp.calculate_qc_metrics(adata, inplace=True)

    # 8. å¯é€‰ï¼šåŠ è½½å·²ä½¿ç”¨çš„barcodeåˆ—è¡¨
    if 'used_barcodes_file' in config['data'] and config['data']['used_barcodes_file']:
        used_barcodes_file = config['data']['used_barcodes_file']
        if not os.path.exists(used_barcodes_file):
            raise FileNotFoundError(f"æŒ‡å®šçš„ used_barcodes_file ä¸å­˜åœ¨: {used_barcodes_file}")

        try:
            used_barcode = pd.read_csv(used_barcodes_file, sep='\t', header=None)[0].astype(str)
        except Exception as e:
            raise ValueError(f"æ— æ³•è¯»å– used_barcodes_file '{used_barcodes_file}'ï¼Œåº”ä¸ºå•åˆ—æ–‡æœ¬æ–‡ä»¶ã€‚é”™è¯¯è¯¦æƒ…: {e}")

        used_barcode = used_barcode[used_barcode.isin(adata.obs_names)]
        if len(used_barcode) == 0:
            raise ValueError("used_barcodes_file ä¸­çš„ barcode ä¸å½“å‰ AnnData æ— äº¤é›†ã€‚")
        adata = adata[used_barcode, :]

    # 9. åç»­é¢„å¤„ç†
    sc.pp.filter_genes(adata, min_cells=50)
    sc.pp.highly_variable_genes(adata, flavor="seurat_v3", n_top_genes=config['model']['n_top_genes'])
    sc.pp.normalize_total(adata, target_sum=1e4)
    sc.pp.log1p(adata)

    return adata

def Cal_Spatial_Net(adata, rad_cutoff=None, k_cutoff=None, model='Radius', verbose=True):
    """æ„å»ºç©ºé—´é‚»å±…ç½‘ç»œ"""
    assert model in ['Radius', 'KNN']
    if verbose:
        print('------Calculating spatial graph...')
    coor = pd.DataFrame(adata.obsm['spatial'])
    coor.index = adata.obs.index
    coor.columns = ['imagerow', 'imagecol']
    if model == 'Radius':
        nbrs = sklearn.neighbors.NearestNeighbors(radius=rad_cutoff).fit(coor)
        distances, indices = nbrs.radius_neighbors(coor, return_distance=True)
        KNN_list = []
        for it in range(indices.shape[0]):
            KNN_list.append(pd.DataFrame(zip([it] * indices[it].shape[0], indices[it], distances[it])))
    elif model == 'KNN':
        nbrs = sklearn.neighbors.NearestNeighbors(n_neighbors=k_cutoff + 1).fit(coor)
        distances, indices = nbrs.kneighbors(coor)
        KNN_list = []
        for it in range(indices.shape[0]):
            KNN_list.append(pd.DataFrame(zip([it] * indices.shape[1], indices[it, :], distances[it, :])))
    KNN_df = pd.concat(KNN_list)
    KNN_df.columns = ['Cell1', 'Cell2', 'Distance']
    Spatial_Net = KNN_df.copy()
    Spatial_Net = Spatial_Net.loc[Spatial_Net['Distance'] > 0,]
    id_cell_trans = dict(zip(range(coor.shape[0]), np.array(coor.index)))
    Spatial_Net['Cell1'] = Spatial_Net['Cell1'].map(id_cell_trans)
    Spatial_Net['Cell2'] = Spatial_Net['Cell2'].map(id_cell_trans)
    if verbose:
        print('The graph contains %d edges, %d cells.' % (Spatial_Net.shape[0], adata.n_obs))
        print('%.4f neighbors per cell on average.' % (Spatial_Net.shape[0] / adata.n_obs))
    adata.uns['Spatial_Net'] = Spatial_Net

def Stats_Spatial_Net(adata, save_path=None, show_plot=True):
    """ç»Ÿè®¡å¹¶å¯è§†åŒ–ç©ºé—´ç½‘ç»œå±æ€§"""
    Num_edge = adata.uns['Spatial_Net']['Cell1'].shape[0]
    Mean_edge = Num_edge / adata.shape[0]
    plot_df = pd.value_counts(pd.value_counts(adata.uns['Spatial_Net']['Cell1']))
    plot_df = plot_df / adata.shape[0]
    if show_plot:
        fig, ax = plt.subplots(figsize=[3, 2])
        plt.ylabel('Percentage')
        plt.xlabel('')
        plt.title('Number of Neighbors (Mean=%.2f)' % Mean_edge)
        ax.bar(plot_df.index, plot_df)
        if save_path:
            plt.tight_layout()
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()

def Cal_Gene_Similarity_Net(adata, k_neighbors=6, metric='cosine', verbose=True):
    """è®¡ç®—åŸºå› è¡¨è¾¾ç›¸ä¼¼åº¦ç½‘ç»œ"""
    if 'highly_variable' in adata.var.columns:
        adata_Vars = adata[:, adata.var['highly_variable']]
    else:
        adata_Vars = adata
    X = adata_Vars.X.toarray() if hasattr(adata_Vars.X, 'toarray') else adata_Vars.X
    X = X.astype(np.float32)
    # å‘é‡åŒ–è®¡ç®—ç›¸ä¼¼åº¦ï¼Œé¿å…åŒé‡å¾ªç¯
    if metric == 'cosine':
        similarity_matrix = cosine_similarity(X)
    elif metric == 'euclidean':
        similarity_matrix = -euclidean_distances(X)
    elif metric == 'pearson':
        X_mean = X.mean(axis=1, keepdims=True)
        X_centered = X - X_mean
        X_std = X.std(axis=1, keepdims=True)
        X_normalized = np.divide(X_centered, X_std, out=np.zeros_like(X_centered), where=X_std!=0)
        similarity_matrix = np.dot(X_normalized, X_normalized.T) / (X.shape[1] - 1)
    else:
        raise ValueError(f"æœªçŸ¥çš„ç›¸ä¼¼åº¦åº¦é‡: {metric}")
    KNN_list = []
    for i in range(similarity_matrix.shape[0]):
        sorted_indices = np.argsort(-similarity_matrix[i, :])
        closest_cells = sorted_indices[1:k_neighbors + 1]
        closest_distances = similarity_matrix[i, closest_cells]
        KNN_list.append(pd.DataFrame({
            'Cell1': [i] * k_neighbors,
            'Cell2': closest_cells,
            'Distance': closest_distances
        }))
    KNN_df = pd.concat(KNN_list, ignore_index=True)
    id_cell_trans = dict(zip(range(X.shape[0]), adata_Vars.obs.index))
    KNN_df['Cell1'] = KNN_df['Cell1'].map(id_cell_trans)
    KNN_df['Cell2'] = KNN_df['Cell2'].map(id_cell_trans)
    if verbose:
        print('The graph contains %d edges, %d cells.' % (KNN_df.shape[0], adata.n_obs))
        print('%.4f neighbors per cell on average.' % (KNN_df.shape[0] / adata.n_obs))
    adata.uns['Gene_Similarity_Net'] = KNN_df

def build_pyg_graph_from_df(adata: sc.AnnData, net_key: str) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    ä» adata.uns ä¸­çš„ DataFrame ç½‘ç»œæ„å»º PyG æ‰€éœ€çš„ edge_indexã€‚
    è¿”å›: (edge_index, edge_weight)
    """
    df = adata.uns[net_key].copy()
    cell_to_idx = {cell: idx for idx, cell in enumerate(adata.obs_names)}
    df['Cell1'] = df['Cell1'].map(cell_to_idx)
    df['Cell2'] = df['Cell2'].map(cell_to_idx)
    # ç§»é™¤æ˜ å°„å¤±è´¥çš„è¡Œ (NaN)
    df = df.dropna(subset=['Cell1', 'Cell2'])
    df['Cell1'] = df['Cell1'].astype(int)
    df['Cell2'] = df['Cell2'].astype(int)
    edge_index = torch.tensor([df['Cell1'].values, df['Cell2'].values], dtype=torch.long)
    edge_weight = torch.tensor(df['Distance'].values, dtype=torch.float32)
    return edge_index, edge_weight

def create_pyg_data(adata: sc.AnnData, config: dict) -> Data:
    """
    å°† AnnData å¯¹è±¡è½¬æ¢ä¸º PyTorch Geometric çš„ Data å¯¹è±¡ã€‚
    åŒ…å«ç‰¹å¾çŸ©é˜µã€ç©ºé—´è¾¹å’ŒåŸºå› ç›¸ä¼¼æ€§è¾¹ã€‚
    """
    # ç‰¹å¾çŸ©é˜µ (ä»…é«˜å˜åŸºå› )
    if 'highly_variable' in adata.var.columns:
        X = adata[:, adata.var['highly_variable']].X
    else:
        X = adata.X
    X = torch.tensor(X.toarray() if hasattr(X, 'toarray') else X, dtype=torch.float)
    # æ„å»ºä¸¤ç§ç±»å‹çš„è¾¹
    spatial_edge_index, _ = build_pyg_graph_from_df(adata, 'Spatial_Net')  # å¿½ç•¥æƒé‡ï¼ˆGATConv ä¸ä½¿ç”¨ï¼‰
    gene_sim_edge_index, _ = build_pyg_graph_from_df(adata, 'Gene_Similarity_Net')
    # åˆ›å»º PyG Data å¯¹è±¡
    data = Data(
        x=X,
        spatial_edge_index=spatial_edge_index,
        gene_sim_edge_index=gene_sim_edge_index
    )
    return data



============================================================
æ–‡ä»¶: src/__init__.py
============================================================

# src/__init__.py
# This file makes the 'src' directory a Python package.


