=== 项目核心文件内容汇总 ===


============================================================
文件: .gitignore
============================================================

# Directories
data/
logs/
cache/
results/

# Large file extensions
*.zip
*.tar.gz
*.h5
*.h5ad      # 👈 显式加上 .h5ad（你出问题的文件类型）
*.pt
*.pth
*.onnx
*.pb

# Python
*.pyc
__pycache__/

# Text files (only if truly temporary)
default_yaml.txt
gates_model.txt
run_analysis.txt
trainer.txt
utils.txt



============================================================
文件: README.md
============================================================

# GATES Project: Graph Attention Transcriptomics Encoder for Spatial Transcriptomics Analysis

GATES（Graph Attention Transcriptomics Encoder）是一个基于 **PyTorch Geometric** 的深度学习框架，用于分析 **空间转录组学（Spatial Transcriptomics）** 数据。本项目结合空间邻接关系与基因表达相似性，构建异构图结构，并通过图注意力机制进行特征学习，最终实现高精度的组织区域聚类与可视化。

## 📌 项目亮点
- 支持 10x Genomics Visium 等主流空间转录组数据格式
- 自动构建 **空间邻接图 + 基因相似性图**
- 基于 **GAT（Graph Attention Network）** 的端到端训练
- 提供完整的预处理 → 训练 → 聚类 → 可视化流程
- 模块化设计，易于扩展与复用

---

## 📁 项目结构

```
C:.
│  .gitignore
│  LICENSE
│  README.md
│  requirements.txt
│
├─cache                     # 预处理后的缓存数据（.h5ad）
├─configs                   # 配置文件（YAML）
├─data                      # 原始数据（支持多个样本，如 151673, 151674, 151675）
│  └─151673                 # 示例：10x Visium 小鼠脑切片数据
│      │  filtered_feature_bc_matrix.h5
│      │  position.tsv
│      │  metadata.tsv
│      │  truth.txt         # 真实标签（用于评估）
│      └─spatial/
├─results                   # 输出结果（如聚类图）
├─scripts                   # 主运行脚本
│  └─run_analysis.py
└─src                       # 核心源码
    │  gates_model.py       # GATES 模型定义
    │  trainer.py           # 训练逻辑
    │  utils.py             # 工具函数（图构建、预处理等）
    │  pyg.py               # PyG 图数据封装
    └─convert_visium_to_stereo.py  # 数据格式转换工具
```

---

## ⚙️ 安装指南

### 环境要求
- Python ≥ 3.8
- PyTorch ≥ 1.12
- CUDA（推荐，用于加速训练）

### 安装步骤
```bash
# 1. 克隆仓库
git clone https://github.com/your-username/GATES.git
cd GATES

# 2. 安装依赖
pip install -r requirements.txt
```

> 💡 提示：建议使用虚拟环境（如 `conda` 或 `venv`）避免依赖冲突。

---

## ▶️ 快速开始

```bash
cd scripts
python run_analysis.py
```

该脚本将自动：
1. 加载 `data/151673` 中的 Visium 数据
2. 预处理并缓存到 `cache/`
3. 构建空间图与基因相似图
4. 训练 GATES 模型
5. 执行聚类并评估（Silhouette Score, Davies-Bouldin Index）
6. 保存空间聚类图至 `results/spatial_plot.png`

---

## 🛠 配置说明

所有参数均在 `configs/default.yaml` 中管理，包括：

```yaml
# configs/default.yaml
data:
  counts_file: 'C:/Users/admini/Documents/GATES-ST/data/151673/RNA_counts.tsv'
  coor_file: 'C:/Users/admini/Documents/GATES-ST/data/151673/position.tsv'
  used_barcodes_file: 'C:/Users/admini/Documents/GATES-ST/data/151673/used_barcodes.txt'
model:
  alpha: 0.5  # 修正：原值 0.0001 过小，建议 0.1~0.9
  n_top_genes: 3000
  hidden_dims: [512, 30]
  rad_cutoff: 50
  k_neighbors: 6
  similarity_metric: "cosine"
train:
  n_epochs: 1000
  lr: 0.0001
  weight_decay: 0.0001
  key_added: "GATES"
cluster:
  resolution: 1.0
output:
  spatial_plot_path: "results/spatial_plot.png"
  neighbor_stats_plot: 'C:/Users/admini/Documents/GATES-ST/figure/alpha{alpha}_{resolution}_Stereo-seq_Mouse_NumberOfNeighbors.png'
  spatial_plot_crop: [10100, 10721, 13810, 13093]

```

修改该文件即可适配不同数据集或调整超参数。

---

## 📈 输出结果

运行完成后，你将获得：
- **聚类指标**：控制台输出 Silhouette Score 和 Davies-Bouldin Index
- **可视化图**：`results/spatial_plot.png` 展示空间聚类结果（如下示意）

> 🖼️ *示例图：不同颜色代表不同组织区域，与真实解剖结构高度一致*

---

## 📚 数据说明

本项目默认使用 **10x Genomics Visium 公开数据集**：
- `151673`, `151674`, `151675`：小鼠脑组织切片（来自 [10x官方示例](https://support.10xgenomics.com/spatial-gene-expression/datasets)）
- 文件包括：基因表达矩阵（.h5）、空间坐标（tissue_positions_list.csv）、组织图像等

如需使用其他数据（如 Stereo-seq），请参考 `src/convert_visium_to_stereo.py` 进行格式转换。

---

## ❓ 常见问题

**Q: 运行时报错 “CUDA out of memory”？**
A: 尝试减小 `batch_size`（如有）或改用 `device: "cpu"`。

**Q: 如何更换数据集？**
A: 修改 `configs/default.yaml` 中的 `data.root` 路径，并确保目录结构与 151673 一致。

**Q: 能否用于人类组织数据？**
A: 可以！只要提供符合格式的空间表达数据即可。

---

## 📄 许可证

本项目采用 **MIT License** — 详见 [LICENSE](LICENSE) 文件。

---

## 🙏 致谢

- 数据来源：10x Genomics Spatial Gene Expression Datasets
- 技术基础：PyTorch Geometric, Scanpy, scikit-learn
- 若本项目对您的研究有帮助，欢迎引用相关论文（如有）！

---

> 💬 **欢迎提交 Issue 或 Pull Request！** 任何改进建议或 bug 报告都十分感谢！



============================================================
文件: configs/default.yaml
============================================================

# configs/default.yaml
data:
  counts_file: 'data/151673/RNA_counts.tsv'
  coor_file: 'data/151673/position.tsv'
  used_barcodes_file: 'data/151673/used_barcodes.txt'
model:
  alpha: 0.5  # 修正：原值 0.0001 过小，建议 0.1~0.9
  n_top_genes: 3000
  hidden_dims: [512, 30]
  rad_cutoff: 50
  k_neighbors: 6
  similarity_metric: "cosine"
train:
  n_epochs: 10
  lr: 0.0001
  weight_decay: 0.0001
  lambda_spatial: 0.1
  key_added: "GATES"
cluster:
  resolution: 1.0
output:
  spatial_plot_path: "results/spatial_plot.png"
  neighbor_stats_plot: 'figure/alpha{alpha}_{resolution}_Stereo-seq_Mouse_NumberOfNeighbors.png'
  spatial_plot_crop: null



============================================================
文件: configs/requirements.txt
============================================================

[无法读取二进制文件或编码错误: .\configs/requirements.txt]


============================================================
文件: scripts/run_analysis.py
============================================================

# scripts/run_analysis.py
import os
import yaml
import scanpy as sc
import matplotlib.pyplot as plt
from sklearn.metrics import silhouette_score, davies_bouldin_score
from src.utils import load_and_preprocess_data, Cal_Spatial_Net, Stats_Spatial_Net, Cal_Gene_Similarity_Net, create_pyg_data
from src.gates_model import GATES
from src.trainer import GATESTrainer
import squidpy as sq

def main():
    with open('./configs/default.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    # === 新增：定义缓存路径 ===
    cache_dir = "./cache"
    os.makedirs(cache_dir, exist_ok=True)
    cache_file = os.path.join(
        cache_dir,
        f"preprocessed_adata_rad{config['model']['rad_cutoff']}_k{config['model']['k_neighbors']}.h5ad"
    )

    print('------------------')
    alpha = config['model']['alpha']
    resolution = config['cluster']['resolution']

    # === 检查缓存是否存在 ===
    if os.path.exists(cache_file):
        print(f"Loading cached preprocessed data from {cache_file}...")
        adata = sc.read_h5ad(cache_file)
        print(f'Loaded cached data: {adata.shape}')
    else:
        print("Loading and preprocessing data...")
        adata = load_and_preprocess_data(config)
        print(f'After filtering: {adata.shape}')

        print("Building spatial network...")
        Cal_Spatial_Net(adata, rad_cutoff=config['model']['rad_cutoff'], model='Radius', verbose=True)
        Stats_Spatial_Net(adata, save_path=config['output']['neighbor_stats_plot'].format(alpha=alpha, resolution=resolution), show_plot=False)

        print("Building gene similarity network...")
        Cal_Gene_Similarity_Net(
            adata,
            k_neighbors=config['model']['k_neighbors'],
            metric=config['model']['similarity_metric'],
            verbose=True
        )

        # === 保存到缓存 ===
        print(f"Saving preprocessed data to cache: {cache_file}")
        adata.write_h5ad(cache_file)
    print("Preparing PyG data...")
    pyg_data = create_pyg_data(adata, config)
    # 确保输入维度正确：高变基因数量
    in_channels = adata.var['highly_variable'].sum() if 'highly_variable' in adata.var else adata.n_vars
    hidden_channels = config['model']['hidden_dims'][0]
    out_channels = config['model']['hidden_dims'][1]
    print(f"Model input dim: {in_channels}, hidden: {hidden_channels}, output: {out_channels}")
    print("Initializing and training GATES model...")
    print("hidden_dims:", config['model']['hidden_dims'])
    print("type:", type(config['model']['hidden_dims']))
    model = GATES(
        in_channels = int(adata.var['highly_variable'].sum()) if 'highly_variable' in adata.var else int(adata.n_vars),
        hidden_channels = int(config['model']['hidden_dims'][0]),
        out_channels = int(config['model']['hidden_dims'][1]),
        alpha=alpha
    )
    trainer = GATESTrainer(model, config)
    trainer.train(pyg_data, n_epochs=config['train']['n_epochs'])
    print("Inferring embeddings...")
    embeddings = trainer.infer(pyg_data)
    adata.obsm[config['train']['key_added']] = embeddings
    print("Performing clustering and UMAP...")
    sc.pp.neighbors(adata, use_rep=config['train']['key_added'])
    sc.tl.umap(adata)
    sc.tl.louvain(adata, resolution=resolution)
    adata.obs['louvain'] = adata.obs['louvain'].astype('category')  # 👈 新增这行！
    louvain_labels = adata.obs['louvain'].astype(int)

    # 修正：使用 GATES 嵌入计算指标，而非 UMAP
    sc_score = silhouette_score(embeddings, louvain_labels)
    db_score = davies_bouldin_score(embeddings, louvain_labels)

    print(f'Silhouette Coefficient: {sc_score:.4f}')
    print(f'Davies-Bouldin Index: {db_score:.4f}')
    print("Generating plots...")
    crop_coord = config['output']['spatial_plot_crop']
    plt.rcParams["figure.figsize"] = (5, 4)

    print("Generating plots...")
    crop_coord = config['output']['spatial_plot_crop']
    plt.rcParams["figure.figsize"] = (5, 4)

    # 优先从 config 获取完整路径，否则用默认名 + 输出目录
    output_path = config['output'].get('spatial_plot_path')
    if output_path is None:
        output_dir = config['output'].get('dir', '.')
        output_path = os.path.join(output_dir, "spatial_louvain.png")

    # 确保目录存在
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    print("Spatial coordinates range:")
    print("x:", adata.obsm["spatial"][:, 0].min(), "to", adata.obsm["spatial"][:, 0].max())
    print("y:", adata.obsm["spatial"][:, 1].min(), "to", adata.obsm["spatial"][:, 1].max())
    print("Crop coord:", crop_coord)
    print("Spatial coordinates shape:", adata.obsm["spatial"].shape)
    print("First few spatial coords:\n", adata.obsm["spatial"][:5])
    print("Louvain labels info:")
    print("Unique labels:", adata.obs['louvain'].unique())
    print("Number of NaNs:", adata.obs['louvain'].isna().sum())
    print("Data type:", adata.obs['louvain'].dtype)

    # 替换原来的 sc.pl.spatial 调用
    sq.pl.spatial_scatter(
        adata,
        color="louvain",
        shape=None,  # 不显示组织轮廓（可选）
        size=20,     # 对应 spot_size
        title=f'Ours SC{sc_score:.2f} DB{db_score:.2f}',
        save=output_path  # 自动保存，无需 plt.savefig
    )

    plt.axis('off')
    plt.tight_layout()
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    plt.close()

    print(f"Spatial plot saved to: {output_path}")
    success_art = r"""


    ___ _   _  ___ ___ ___  ___ ___
    / __| | | |/ __/ __/ _ \/ __/ __|
    \__ \ |_| | (_| (_|  __/\__ \__ \
    |___/\__,_|\___\___\___||___/___/


    """

    print("\033[1;32m" + success_art + "\033[0m")
    print("\033[1;36m✨ Analysis completed successfully! All results saved. ✨\033[0m")
    print("\033[1;33m🎉 You're awesome! Go celebrate with a coffee! ☕\033[0m")

if __name__ == "__main__":
    main()



============================================================
文件: src/Check_gpu_available.py
============================================================

## torch
import torch

# 检查 CUDA 是否可用
print(f"CUDA available: {torch.cuda.is_available()}")

# 检查可用的 GPU 数量
print(f"Number of GPUs: {torch.cuda.device_count()}")

# 获取当前 GPU 设备索引
if torch.cuda.is_available():
    print(f"Current GPU: {torch.cuda.current_device()}")
    print(f"GPU name: {torch.cuda.get_device_name(torch.cuda.current_device())}")

    # 创建一个在 GPU 上的张量来测试
    x = torch.randn(1000, 1000).cuda()
    y = torch.randn(1000, 1000).cuda()
    z = torch.mm(x, y)
    print("GPU computation test passed!")



============================================================
文件: src/convert_visium_to_stereo.py
============================================================

import sys
sys.modules['torch'] = None  # 阻止 anndata 导入 torch

import scanpy as sc
import pandas as pd
import os
# ... 后续代码不变
import scanpy as sc
import pandas as pd
import os

print("开始转换...")
# ===== 配置路径 =====
input_h5 = r"C:\Users\admini\Documents\GATES-ST\data\151673\filtered_feature_bc_matrix.h5"
input_pos = r"C:\Users\admini\Documents\GATES-ST\data\151673\spatial\tissue_positions_list.csv"
output_dir = r"C:\Users\admini\Documents\GATES-ST\data\151673"

# ===== 1. 读取表达矩阵 =====
adata = sc.read_10x_h5(input_h5)
# 转置：行=基因，列=barcode（TSV 通常这样）
df_counts = adata.to_df().T  # shape: (n_genes, n_barcodes)
df_counts.to_csv(os.path.join(output_dir, "RNA_counts.tsv"), sep="\t")

print("RNA_counts.tsv 已保存")
# ===== 2. 读取坐标文件 =====
# Visium 的 tissue_positions_list.csv 格式（无 header）：
# barcode, in_tissue, array_row, array_col, pxl_row_in_fullres, pxl_col_in_fullres
pos_df = pd.read_csv(input_pos, header=None)
pos_df.columns = ["barcode", "in_tissue", "array_row", "array_col", "pxl_row", "pxl_col"]

# 只保留 in_tissue == 1 的 spots（即组织内的有效点）
used_barcodes = pos_df[pos_df["in_tissue"] == 1]["barcode"].tolist()

# 保存 used_barcodes.txt
with open(os.path.join(output_dir, "used_barcodes.txt"), "w") as f:
    f.write("\n".join(used_barcodes))

print("✅ 已保存 used_barcodes.txt")
# 保存 position.tsv（格式：barcode, x, y）
# 注意：Visium 坐标常用 pxl_col (x), pxl_row (y)，但有些工具用 array_col/array_row
# 这里用高分辨率图像坐标（pxl_col, pxl_row），你也可以根据需求换
# ✅ 正确：使用高分辨率像素坐标 (pxl_col, pxl_row)
pos_used = pos_df[pos_df["in_tissue"] == 1][["barcode", "pxl_col", "pxl_row"]]
pos_used.to_csv(os.path.join(output_dir, "position.tsv"), sep="\t", index=False, header=False)

print("✅ 三个文件已生成！")
print("- RNA_counts.tsv")
print("- position.tsv")
print("- used_barcodes.txt")



============================================================
文件: src/gates_model.py
============================================================

# src/gates_model.py
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GATConv

class GATES(nn.Module):
    """
    GATES (Graph Attention Encoder) 模型
    使用两个独立的 GAT 层分别处理空间网络和基因相似性网络，然后进行加权融合。
    """
    def __init__(self, in_channels: int, hidden_channels: int, out_channels: int, alpha: float = 0.5):
        """
        初始化模型。
        Args:
            in_channels: 输入特征维度
            hidden_channels: 隐藏层维度
            out_channels: 输出嵌入维度
            alpha: 基因相似性网络的权重，最终融合为: alpha * gene_sim + (1-alpha) * spatial
        """
        super().__init__()
        self.alpha = alpha
        # 编码器部分
        self.spatial_gat = GATConv(in_channels, hidden_channels, add_self_loops=True, concat=False)
        self.gene_sim_gat = GATConv(in_channels, hidden_channels, add_self_loops=True, concat=False)
        self.fusion_gat = GATConv(hidden_channels, out_channels, add_self_loops=True, concat=False)
        # 解码器：用于重构输入（仅训练时使用）
        self.decoder = nn.Sequential(
            nn.Linear(out_channels, hidden_channels),
            nn.ELU(),
            nn.Linear(hidden_channels, in_channels)
        )

    def forward(self, x: torch.Tensor, spatial_edge_index: torch.Tensor, gene_sim_edge_index: torch.Tensor):
        """
        返回嵌入和重构输出（用于训练）
        """
        h_spatial = F.elu(self.spatial_gat(x, spatial_edge_index))
        h_gene_sim = F.elu(self.gene_sim_gat(x, gene_sim_edge_index))
        h_fused = self.alpha * h_gene_sim + (1 - self.alpha) * h_spatial
        # 使用空间图进行最终融合（符合空间转录组特性）
        embeddings = self.fusion_gat(h_fused, spatial_edge_index)
        recon = self.decoder(embeddings)
        return embeddings, recon

    def encode(self, x: torch.Tensor, spatial_edge_index: torch.Tensor, gene_sim_edge_index: torch.Tensor):
        """
        仅返回嵌入（用于推理）
        """
        h_spatial = F.elu(self.spatial_gat(x, spatial_edge_index))
        h_gene_sim = F.elu(self.gene_sim_gat(x, gene_sim_edge_index))
        h_fused = self.alpha * h_gene_sim + (1 - self.alpha) * h_spatial
        embeddings = self.fusion_gat(h_fused, spatial_edge_index)
        return embeddings



============================================================
文件: src/pyg.py
============================================================

import torch

torch_version = torch.__version__.split('+')[0]
cuda_version = torch.version.cuda
cuda_str = f"cu{cuda_version.replace('.', '')}" if cuda_version else "cpu"

print(f"pip install torch_geometric torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-{torch_version}+{cuda_str}.html")



============================================================
文件: src/trainer.py
============================================================

# src/trainer.py
import torch
import torch.optim as optim
from tqdm import tqdm
from .gates_model import GATES
from typing import Dict, Any
import torch.nn.functional as F
from torch_geometric.data import Data

class GATESTrainer:
    """
    GATES 模型训练器
    """
    def __init__(self, model: GATES, config: Dict[str, Any]):
        self.model = model
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        self.optimizer = optim.Adam(
            self.model.parameters(),
            lr=config['train']['lr'],
            weight_decay=config['train']['weight_decay']
        )
        self.loss_history = []

    def train(self, data: Data, n_epochs: int) -> None:
        """
        训练模型。
        Args:
            data: PyG Data 对象（不是 DataLoader）
            n_epochs: 训练轮数
        """
        self.model.train()
        data = data.to(self.device)
        spatial_edge_index = data.spatial_edge_index  # [2, E]

        # 从配置中读取空间正则化权重（默认为 0.0，即不启用）
        lambda_spatial = self.config['train'].get('lambda_spatial', 0.0)

        for epoch in tqdm(range(n_epochs), desc="Training"):
            self.optimizer.zero_grad()
            embeddings, recon = self.model(data.x, spatial_edge_index, data.gene_sim_edge_index)

            # 1. 重构损失（MSE）
            recon_loss = F.mse_loss(recon, data.x)

            # 2. 空间一致性正则项（仅当 lambda_spatial > 0 时计算）
            spatial_loss = 0.0
            if lambda_spatial > 0.0:
                z_i = embeddings[spatial_edge_index[0]]  # source 节点嵌入
                z_j = embeddings[spatial_edge_index[1]]  # target 节点嵌入
                spatial_loss = F.mse_loss(z_i, z_j)      # ||z_i - z_j||^2 的均值

            # 3. 总损失
            total_loss = recon_loss + lambda_spatial * spatial_loss

            total_loss.backward()
            self.optimizer.step()
            self.loss_history.append(total_loss.item())

            if epoch % 100 == 0:
                print(f"Epoch {epoch}, Recon Loss: {recon_loss.item():.4f}", end="")
                if lambda_spatial > 0.0:
                    print(f", Spatial Loss: {spatial_loss.item():.4f}", end="")
                print(f", Total Loss: {total_loss.item():.4f}")

    def infer(self, data: Data) -> torch.Tensor:
        """
        使用训练好的模型进行推理。
        """
        self.model.eval()
        data = data.to(self.device)
        with torch.no_grad():
            embeddings = self.model.encode(data.x, data.spatial_edge_index, data.gene_sim_edge_index)
        return embeddings.cpu().numpy()



============================================================
文件: src/utils.py
============================================================

# src/utils.py
import os
import pandas as pd
import numpy as np
import scanpy as sc
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
from scipy.stats import pearsonr
import matplotlib.pyplot as plt
from typing import Tuple
import torch
from torch_geometric.data import Data
import sklearn

def load_and_preprocess_data(config: dict) -> sc.AnnData:
    # 1. 检查并加载计数矩阵
    counts_file = config['data']['counts_file']
    if not os.path.exists(counts_file):
        raise FileNotFoundError(f"计数矩阵文件不存在: {counts_file}")

    try:
        counts = pd.read_csv(counts_file, sep='\t', index_col=0)
    except Exception as e:
        raise ValueError(f"无法读取计数矩阵文件 '{counts_file}'，请检查文件格式是否为制表符分隔的文本文件（TSV），且第一列为基因名。错误详情: {e}")

    # 2. 检查并加载坐标文件
    coor_file = config['data']['coor_file']
    if not os.path.exists(coor_file):
        raise FileNotFoundError(f"空间坐标文件不存在: {coor_file}")

    try:
        coor_df = pd.read_csv(coor_file, sep='\t', header=None)
    except Exception as e:
        raise ValueError(f"无法读取坐标文件 '{coor_file}'，请确保其为制表符分隔的三列文本文件（barcode, x, y），无表头。错误详情: {e}")

    if coor_df.shape[1] < 3:
        raise ValueError(f"坐标文件 '{coor_file}' 至少应包含三列（barcode, x, y），当前只有 {coor_df.shape[1]} 列。")

    coor_df.columns = ['barcode', 'x', 'y']
    coor_df = coor_df.set_index('barcode')

    # 3. 确保索引类型一致（字符串）
    counts.columns = counts.columns.astype(str)
    coor_df.index = coor_df.index.astype(str)

    # 4. 创建 AnnData（cells × genes）
    adata = sc.AnnData(counts.T)
    adata.var_names_make_unique()

    # 5. 对齐表达数据和坐标（取交集）
    common_barcodes = adata.obs_names.intersection(coor_df.index)
    if len(common_barcodes) == 0:
        raise ValueError("计数矩阵的列名（细胞barcode）与坐标文件的barcode无交集，请检查两者是否匹配。")

    adata = adata[common_barcodes, :]
    coor_df = coor_df.loc[common_barcodes]

    # 6. 设置空间坐标 [x, y]
    adata.obsm["spatial"] = coor_df[['x', 'y']].values

    # 7. QC 和标准化（保持不变）
    sc.pp.calculate_qc_metrics(adata, inplace=True)

    # 8. 可选：加载已使用的barcode列表
    if 'used_barcodes_file' in config['data'] and config['data']['used_barcodes_file']:
        used_barcodes_file = config['data']['used_barcodes_file']
        if not os.path.exists(used_barcodes_file):
            raise FileNotFoundError(f"指定的 used_barcodes_file 不存在: {used_barcodes_file}")

        try:
            used_barcode = pd.read_csv(used_barcodes_file, sep='\t', header=None)[0].astype(str)
        except Exception as e:
            raise ValueError(f"无法读取 used_barcodes_file '{used_barcodes_file}'，应为单列文本文件。错误详情: {e}")

        used_barcode = used_barcode[used_barcode.isin(adata.obs_names)]
        if len(used_barcode) == 0:
            raise ValueError("used_barcodes_file 中的 barcode 与当前 AnnData 无交集。")
        adata = adata[used_barcode, :]

    # 9. 后续预处理
    sc.pp.filter_genes(adata, min_cells=50)
    sc.pp.highly_variable_genes(adata, flavor="seurat_v3", n_top_genes=config['model']['n_top_genes'])
    sc.pp.normalize_total(adata, target_sum=1e4)
    sc.pp.log1p(adata)

    return adata

def Cal_Spatial_Net(adata, rad_cutoff=None, k_cutoff=None, model='Radius', verbose=True):
    """构建空间邻居网络"""
    assert model in ['Radius', 'KNN']
    if verbose:
        print('------Calculating spatial graph...')
    coor = pd.DataFrame(adata.obsm['spatial'])
    coor.index = adata.obs.index
    coor.columns = ['imagerow', 'imagecol']
    if model == 'Radius':
        nbrs = sklearn.neighbors.NearestNeighbors(radius=rad_cutoff).fit(coor)
        distances, indices = nbrs.radius_neighbors(coor, return_distance=True)
        KNN_list = []
        for it in range(indices.shape[0]):
            KNN_list.append(pd.DataFrame(zip([it] * indices[it].shape[0], indices[it], distances[it])))
    elif model == 'KNN':
        nbrs = sklearn.neighbors.NearestNeighbors(n_neighbors=k_cutoff + 1).fit(coor)
        distances, indices = nbrs.kneighbors(coor)
        KNN_list = []
        for it in range(indices.shape[0]):
            KNN_list.append(pd.DataFrame(zip([it] * indices.shape[1], indices[it, :], distances[it, :])))
    KNN_df = pd.concat(KNN_list)
    KNN_df.columns = ['Cell1', 'Cell2', 'Distance']
    Spatial_Net = KNN_df.copy()
    Spatial_Net = Spatial_Net.loc[Spatial_Net['Distance'] > 0,]
    id_cell_trans = dict(zip(range(coor.shape[0]), np.array(coor.index)))
    Spatial_Net['Cell1'] = Spatial_Net['Cell1'].map(id_cell_trans)
    Spatial_Net['Cell2'] = Spatial_Net['Cell2'].map(id_cell_trans)
    if verbose:
        print('The graph contains %d edges, %d cells.' % (Spatial_Net.shape[0], adata.n_obs))
        print('%.4f neighbors per cell on average.' % (Spatial_Net.shape[0] / adata.n_obs))
    adata.uns['Spatial_Net'] = Spatial_Net

def Stats_Spatial_Net(adata, save_path=None, show_plot=True):
    """统计并可视化空间网络属性"""
    Num_edge = adata.uns['Spatial_Net']['Cell1'].shape[0]
    Mean_edge = Num_edge / adata.shape[0]
    plot_df = pd.value_counts(pd.value_counts(adata.uns['Spatial_Net']['Cell1']))
    plot_df = plot_df / adata.shape[0]
    if show_plot:
        fig, ax = plt.subplots(figsize=[3, 2])
        plt.ylabel('Percentage')
        plt.xlabel('')
        plt.title('Number of Neighbors (Mean=%.2f)' % Mean_edge)
        ax.bar(plot_df.index, plot_df)
        if save_path:
            plt.tight_layout()
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.show()

def Cal_Gene_Similarity_Net(adata, k_neighbors=6, metric='cosine', verbose=True):
    """计算基因表达相似度网络"""
    if 'highly_variable' in adata.var.columns:
        adata_Vars = adata[:, adata.var['highly_variable']]
    else:
        adata_Vars = adata
    X = adata_Vars.X.toarray() if hasattr(adata_Vars.X, 'toarray') else adata_Vars.X
    X = X.astype(np.float32)
    # 向量化计算相似度，避免双重循环
    if metric == 'cosine':
        similarity_matrix = cosine_similarity(X)
    elif metric == 'euclidean':
        similarity_matrix = -euclidean_distances(X)
    elif metric == 'pearson':
        X_mean = X.mean(axis=1, keepdims=True)
        X_centered = X - X_mean
        X_std = X.std(axis=1, keepdims=True)
        X_normalized = np.divide(X_centered, X_std, out=np.zeros_like(X_centered), where=X_std!=0)
        similarity_matrix = np.dot(X_normalized, X_normalized.T) / (X.shape[1] - 1)
    else:
        raise ValueError(f"未知的相似度度量: {metric}")
    KNN_list = []
    for i in range(similarity_matrix.shape[0]):
        sorted_indices = np.argsort(-similarity_matrix[i, :])
        closest_cells = sorted_indices[1:k_neighbors + 1]
        closest_distances = similarity_matrix[i, closest_cells]
        KNN_list.append(pd.DataFrame({
            'Cell1': [i] * k_neighbors,
            'Cell2': closest_cells,
            'Distance': closest_distances
        }))
    KNN_df = pd.concat(KNN_list, ignore_index=True)
    id_cell_trans = dict(zip(range(X.shape[0]), adata_Vars.obs.index))
    KNN_df['Cell1'] = KNN_df['Cell1'].map(id_cell_trans)
    KNN_df['Cell2'] = KNN_df['Cell2'].map(id_cell_trans)
    if verbose:
        print('The graph contains %d edges, %d cells.' % (KNN_df.shape[0], adata.n_obs))
        print('%.4f neighbors per cell on average.' % (KNN_df.shape[0] / adata.n_obs))
    adata.uns['Gene_Similarity_Net'] = KNN_df

def build_pyg_graph_from_df(adata: sc.AnnData, net_key: str) -> Tuple[torch.Tensor, torch.Tensor]:
    """
    从 adata.uns 中的 DataFrame 网络构建 PyG 所需的 edge_index。
    返回: (edge_index, edge_weight)
    """
    df = adata.uns[net_key].copy()
    cell_to_idx = {cell: idx for idx, cell in enumerate(adata.obs_names)}
    df['Cell1'] = df['Cell1'].map(cell_to_idx)
    df['Cell2'] = df['Cell2'].map(cell_to_idx)
    # 移除映射失败的行 (NaN)
    df = df.dropna(subset=['Cell1', 'Cell2'])
    df['Cell1'] = df['Cell1'].astype(int)
    df['Cell2'] = df['Cell2'].astype(int)
    edge_index = torch.tensor([df['Cell1'].values, df['Cell2'].values], dtype=torch.long)
    edge_weight = torch.tensor(df['Distance'].values, dtype=torch.float32)
    return edge_index, edge_weight

def create_pyg_data(adata: sc.AnnData, config: dict) -> Data:
    """
    将 AnnData 对象转换为 PyTorch Geometric 的 Data 对象。
    包含特征矩阵、空间边和基因相似性边。
    """
    # 特征矩阵 (仅高变基因)
    if 'highly_variable' in adata.var.columns:
        X = adata[:, adata.var['highly_variable']].X
    else:
        X = adata.X
    X = torch.tensor(X.toarray() if hasattr(X, 'toarray') else X, dtype=torch.float)
    # 构建两种类型的边
    spatial_edge_index, _ = build_pyg_graph_from_df(adata, 'Spatial_Net')  # 忽略权重（GATConv 不使用）
    gene_sim_edge_index, _ = build_pyg_graph_from_df(adata, 'Gene_Similarity_Net')
    # 创建 PyG Data 对象
    data = Data(
        x=X,
        spatial_edge_index=spatial_edge_index,
        gene_sim_edge_index=gene_sim_edge_index
    )
    return data



============================================================
文件: src/__init__.py
============================================================

# src/__init__.py
# This file makes the 'src' directory a Python package.


